{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ea3f4874-a9aa-42f1-9605-b1784a6f48ba",
    "_uuid": "58c82d3b3c4b4305b388a6ac4eeca49d600f9105"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "804d3969-9035-4ceb-bb65-1b8549d729ec",
    "_uuid": "7a7f3af5ef279a9ed26c4d9ee764bd1fb4bdf10e"
   },
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "train = pd.read_json(\"../input/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backgroundDimmer(bandx, inc_angles, lmd=3, alpha=0.1):\n",
    "    lmd = lmd # affects the threshold \n",
    "    alpha = alpha\n",
    "    inc_angles = inc_angles\n",
    "    tmp = []\n",
    "    \n",
    "    for i in range(len(inc_angles)):\n",
    "        if inc_angles[i] == \"na\":\n",
    "            inc_angles[i] = 0\n",
    "            \n",
    "    inc_angle_max = max(inc_angles)\n",
    "    \n",
    "    # for those whose inc_angle is \"na\", we'll simply ignore its inc_angle effect on data, thus we set those value to max\n",
    "    for i in range(len(inc_angles)):\n",
    "        if inc_angles[i] == 0:\n",
    "            inc_angles[i] = inc_angle_max \n",
    "    \n",
    "    for x in range(bandx.shape[0]):\n",
    "        b = bandx[x].flatten()\n",
    "        bvar = np.var(b)\n",
    "        bmax = np.max(b)\n",
    "        bmin = np.min(b)\n",
    "        distance_min_max = bmax - bmin\n",
    "        threshold = bmax - lmd*bvar\n",
    "    \n",
    "        for i in range(b.shape[0]):\n",
    "                if b[i] < threshold:\n",
    "                    b[i] = b[i] - alpha * (np.cos(inc_angles[x]) - np.cos(inc_angle_max)) * \\\n",
    "                        distance_min_max/(bmax - b[i]) * bvar\n",
    "                        \n",
    "                        \n",
    "        b = b.reshape(75,75)\n",
    "        tmp.append(b)\n",
    "        \n",
    "    result = np.dstack(tmp).T\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "829bf7db-fab1-4a2d-9562-0a37c6390d2a",
    "_uuid": "5292632717f11cd01c135dfabfd3cda9318cc639"
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "inc_angles = train.copy()['inc_angle']\n",
    "X_band_7 = (backgroundDimmer(X_band_1, inc_angles) + backgroundDimmer(X_band_2, inc_angles))/2\n",
    "X_train = X_band_7[:, :, :, np.newaxis]\n",
    "# X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "fb15bc53-becc-4e87-88ce-3bc99d45358d",
    "_uuid": "7a68a94f8c617209dfe56a58e291193e963d0f62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "d7a4c0cc-0e96-46ea-960c-89bb80e11b56",
    "_uuid": "4602792c9d531903bd65c3b127a1e6be2c444b2d"
   },
   "outputs": [],
   "source": [
    "#define our model\n",
    "def getModel():\n",
    "    #Building the model\n",
    "    gmodel=Sequential()\n",
    "    #Conv Layer 1\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 1)))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 2\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 3\n",
    "    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 4\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "\n",
    "    #Dense Layers\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Sigmoid Layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "\n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    gmodel.compile(loss='binary_crossentropy',\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])\n",
    "    gmodel.summary()\n",
    "    return gmodel\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "\n",
    "file_path = \"model_weights_b7.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1d690d4a-09ca-417c-8090-2aa417c514dd",
    "_uuid": "a883659e53709da950d04a4e5349c66d77a9422f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.75, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d6bb750a-e882-4429-ad23-4392389f427f",
    "_uuid": "4e6dab11165b7d9515eb32b698851b260f0d941f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 73, 73, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 559,041\n",
      "Trainable params: 559,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/40\n",
      "1203/1203 [==============================] - 5s - loss: 0.8105 - acc: 0.5145 - val_loss: 0.6800 - val_acc: 0.6559\n",
      "Epoch 2/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.6060 - acc: 0.6126 - val_loss: 0.5347 - val_acc: 0.5960\n",
      "Epoch 3/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.5277 - acc: 0.7307 - val_loss: 0.7240 - val_acc: 0.5486\n",
      "Epoch 4/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.5240 - acc: 0.7382 - val_loss: 0.5212 - val_acc: 0.6459\n",
      "Epoch 5/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4961 - acc: 0.7598 - val_loss: 0.5321 - val_acc: 0.6658\n",
      "Epoch 6/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4872 - acc: 0.7573 - val_loss: 0.5016 - val_acc: 0.6908\n",
      "Epoch 7/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4734 - acc: 0.7664 - val_loss: 0.5403 - val_acc: 0.6733\n",
      "Epoch 8/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4630 - acc: 0.7814 - val_loss: 0.4825 - val_acc: 0.7307\n",
      "Epoch 9/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4280 - acc: 0.7922 - val_loss: 0.4887 - val_acc: 0.7481\n",
      "Epoch 10/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4383 - acc: 0.7980 - val_loss: 0.5491 - val_acc: 0.6633\n",
      "Epoch 11/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4197 - acc: 0.8155 - val_loss: 0.4433 - val_acc: 0.7830\n",
      "Epoch 12/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.3941 - acc: 0.8055 - val_loss: 0.4254 - val_acc: 0.8005\n",
      "Epoch 13/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.3991 - acc: 0.8155 - val_loss: 0.4242 - val_acc: 0.7905\n",
      "Epoch 14/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4026 - acc: 0.8063 - val_loss: 0.4128 - val_acc: 0.7980\n",
      "Epoch 15/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.3431 - acc: 0.8387 - val_loss: 0.3586 - val_acc: 0.8329\n",
      "Epoch 16/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.3367 - acc: 0.8479 - val_loss: 0.6077 - val_acc: 0.7132\n",
      "Epoch 17/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.4023 - acc: 0.8071 - val_loss: 0.3262 - val_acc: 0.8603\n",
      "Epoch 18/40\n",
      "1203/1203 [==============================] - 2s - loss: 0.3211 - acc: 0.8462 - val_loss: 0.4231 - val_acc: 0.7656\n",
      "Epoch 19/40\n",
      "1203/1203 [==============================] - 2s - loss: 0.3139 - acc: 0.8554 - val_loss: 0.4422 - val_acc: 0.7531\n",
      "Epoch 20/40\n",
      "1203/1203 [==============================] - 2s - loss: 0.3215 - acc: 0.8529 - val_loss: 0.3334 - val_acc: 0.8529\n",
      "Epoch 21/40\n",
      "1203/1203 [==============================] - 2s - loss: 0.3045 - acc: 0.8537 - val_loss: 0.3605 - val_acc: 0.8155\n",
      "Epoch 22/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2789 - acc: 0.8678 - val_loss: 0.3048 - val_acc: 0.8529\n",
      "Epoch 23/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2845 - acc: 0.8745 - val_loss: 0.3183 - val_acc: 0.8504\n",
      "Epoch 24/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2561 - acc: 0.8828 - val_loss: 0.3978 - val_acc: 0.7930\n",
      "Epoch 25/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2706 - acc: 0.8761 - val_loss: 0.3178 - val_acc: 0.8628\n",
      "Epoch 26/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2684 - acc: 0.8745 - val_loss: 0.2793 - val_acc: 0.8803\n",
      "Epoch 27/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2422 - acc: 0.8836 - val_loss: 0.3431 - val_acc: 0.8304\n",
      "Epoch 28/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2524 - acc: 0.8853 - val_loss: 0.3043 - val_acc: 0.8628\n",
      "Epoch 29/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2330 - acc: 0.8894 - val_loss: 0.3260 - val_acc: 0.8329\n",
      "Epoch 30/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2493 - acc: 0.8845 - val_loss: 0.3747 - val_acc: 0.8354\n",
      "Epoch 31/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2986 - acc: 0.8728 - val_loss: 0.3794 - val_acc: 0.8155\n",
      "Epoch 32/40\n",
      "1203/1203 [==============================] - 3s - loss: 0.2368 - acc: 0.8845 - val_loss: 0.4042 - val_acc: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f268bfa2a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Without denoising, core features.\n",
    "import os\n",
    "gmodel=getModel()\n",
    "gmodel.fit(X_train_cv, y_train_cv,\n",
    "          batch_size=24,\n",
    "          epochs=40,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "079f0a8d-d2a5-4154-b37f-b425333e4ada",
    "_uuid": "0fa65f37d198cd6301376f179d9de0ccc1d40db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s     \n",
      "Test loss: 0.279342494032\n",
      "Test accuracy: 0.880299254546\n"
     ]
    }
   ],
   "source": [
    "gmodel.load_weights(filepath=file_path)\n",
    "score = gmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
